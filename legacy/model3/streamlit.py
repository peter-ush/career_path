# streamlit.py
import os
import json
import re
from typing import Optional

import streamlit as st

from langchain_openai import ChatOpenAI
from langchain.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

from src.app.schemas import (
    UserProfile,
    ExtractionResult,
    merge_profile,
    compute_filled_and_missing,
)
from dotenv import load_dotenv

load_dotenv()


# -------------------------
# Prompts (2-pass)
# -------------------------
DIALOGUE_SYSTEM_PROMPT = """\
ë„ˆëŠ” í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ëŠ” IT ì§„ë¡œ/ì§ë¬´ ìƒë‹´ ì±—ë´‡ì´ë‹¤.
ì‚¬ìš©ìê°€ 'ë©´ì ‘/ì„¤ë¬¸'ì²˜ëŸ¼ ëŠë¼ì§€ ì•Šê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ìƒë‹´í•´ì•¼ í•œë‹¤.

[ëŒ€í™” í†¤/êµ¬ì¡°(ê°•ì œ)]
- ë§¤ í„´ ê¸°ë³¸ êµ¬ì¡°ëŠ” E-S-V ì´ë‹¤.
  E(ê³µê°/ë°›ì•„ì£¼ê¸°) 1ë¬¸ì¥
  S(ìš”ì•½/ì •ë¦¬) 1ë¬¸ì¥: ì‚¬ìš©ìê°€ ë§í•œ ê²ƒë§Œ ìš”ì•½(ìƒìƒ ê¸ˆì§€)
  V(ê°€ì¹˜ ì œê³µ) 2~4ë¬¸ì¥: ë°©í–¥ ì œì‹œ/ì„ íƒì§€/ì§§ì€ ì „ëµ
- Q(ì§ˆë¬¸)ëŠ” policy.ask_question == trueì¼ ë•Œë§Œ "ë”± 1ê°œ" í•œë‹¤.
  ì§ˆë¬¸ì€ ê°€ë³ê³  ì—´ë¦° ì§ˆë¬¸ìœ¼ë¡œ, ì˜ˆì‹œëŠ” ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ.
  ì ˆëŒ€ ì—¬ëŸ¬ ì§ˆë¬¸ì„ í•œêº¼ë²ˆì— í•˜ì§€ ë§ˆë¼.

[ì¶”ì²œ ê·œì¹™(ê°•ì œ)]
- ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì¶”ì²œì„ ìš”êµ¬í•œ ê²½ìš°(user_intent=ASK_RECOMMEND)ì—ë§Œ
  ì§ë¬´ í›„ë³´(Top3/íƒìƒ‰ìš©)ë¥¼ 'ëª©ë¡ í˜•íƒœ'ë¡œ ì œì‹œí•  ìˆ˜ ìˆë‹¤.
- ê·¸ ì™¸(user_intent=GREET/CAREER)ì—ëŠ” ì¶”ì²œ ëª©ë¡ì„ ë¨¼ì € ë˜ì§€ì§€ ë§ ê²ƒ.
  ëŒ€ì‹  ìƒë‹´(ë°©í–¥ ì¡ê¸°/ê¸°ì¤€ ì„¸ìš°ê¸°/ë‹¤ìŒ ì•¡ì…˜) ì¤‘ì‹¬ìœ¼ë¡œ ë§í•œë‹¤.

[í˜„ì¬ ìƒíƒœ]
- user_intent: {user_intent}  # GREET / CAREER / ASK_RECOMMEND
- filled_count: {filled_count}
- missing_slots: {missing_slots}
- current_profile_json: {current_profile_json}

[policy]
- ask_question: {ask_question}  # true/false
- question_focus: {question_focus}  # ì–´ë–¤ ì£¼ì œë¡œ 1ê°œ ì§ˆë¬¸í• ì§€ (ì—†ìœ¼ë©´ "none")
- reco_mode: {reco_mode}  # NONE / EXPLORE / TOP3_CANDIDATES / TOP3_FINAL
  * reco_modeëŠ” ASK_RECOMMENDì¼ ë•Œë§Œ NONEì´ ì•„ë‹ ìˆ˜ ìˆìŒ

ì¶œë ¥ì€ ìì—°ì–´ í…ìŠ¤íŠ¸ë§Œ. (JSON ì¶œë ¥ ê¸ˆì§€)
"""

EXTRACT_SYSTEM_PROMPT = """\
ë„ˆëŠ” ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ 'ëª…ì‹œì ìœ¼ë¡œ ë§í•œ ì •ë³´ë§Œ' êµ¬ì¡°í™”í•´ì„œ ì¶”ì¶œí•˜ëŠ” ì •ë³´ì¶”ì¶œê¸°ë‹¤.

[ì¶”ì¶œ ëŒ€ìƒ ìŠ¬ë¡¯(6ê°œ)]
- project_experience (ProjectItem): title/summary/tech_stack/domain ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì¶”ì¶œ ê°€ëŠ¥
- project_role (list[str])
- languages (list[LanguageSkill]): name + level(unknown/beginner/intermediate/advanced/expert)
- preferred_work (list[str])
- interests (list[str])
- major (str)

[ì¤‘ìš” ê·œì¹™]
- ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ì¸¡í•´ì„œ ì±„ìš°ì§€ ë§ˆë¼.
- ì• ë§¤í•˜ë©´ Noneìœ¼ë¡œ ë‘¬ë¼.
- user_messageë§Œ ê·¼ê±°ë¡œ ì‚¼ì•„ë¼. assistant ë©”ì‹œì§€ì—ì„œ ìœ ì¶”í•˜ì§€ ë§ˆë¼.

ì•„ë˜ ìŠ¤í‚¤ë§ˆë¥¼ ë§Œì¡±í•˜ëŠ” JSONë§Œ ì¶œë ¥í•˜ë¼. JSON ë°– í…ìŠ¤íŠ¸ ê¸ˆì§€.

{format_instructions}
"""

# -------------------------
# Intent + Policy
# -------------------------
ASK_RECOMMEND_KEYWORDS = [
    "ì¶”ì²œí•´ì¤˜", "ì¶”ì²œí•´", "ì§ë¬´ ì¶”ì²œ", "ì§ë¬´ ë­ê°€", "ë­ê°€ ë§ì•„", "íƒ‘3", "top3", "ê²°ê³¼ ë³´ì—¬ì¤˜", "ì§ë¬´ ë½‘ì•„ì¤˜"
]
GREET_PATTERNS = [
    r"^ì•ˆë…•[!.~ ]*$",
    r"^ì•ˆë…•í•˜ì„¸ìš”[!.~ ]*$",
    r"^(ã…ã…‡|í•˜ì´|hi|hello|hey)[!.~ ]*$",
]


def detect_intent(text: str) -> str:
    t = (text or "").strip().lower()
    if any(re.match(p, t) for p in GREET_PATTERNS):
        return "GREET"
    if any(k in t for k in ASK_RECOMMEND_KEYWORDS):
        return "ASK_RECOMMEND"
    return "CAREER"


QUESTION_PRIORITY = ["interests", "preferred_work", "major", "languages", "project_experience", "project_role"]


def pick_question_focus(missing_slots: list[str]) -> str:
    for k in QUESTION_PRIORITY:
        if k in missing_slots:
            return k
    return "none"


def compute_policy(intent: str, filled_count: int, missing_slots: list[str], turns_since_question: int) -> dict:
    policy = {"ask_question": False, "question_focus": "none", "reco_mode": "NONE"}

    if intent == "GREET":
        policy["ask_question"] = True
        policy["question_focus"] = "ê³ ë¯¼"
        return policy

    if intent != "ASK_RECOMMEND":
        # CAREER: ì¶”ì²œì€ ì•ˆ í•¨. ì§ˆë¬¸ì€ 2~3í„´ì— 1ë²ˆ ì •ë„.
        if turns_since_question >= 2:
            policy["ask_question"] = True
            policy["question_focus"] = pick_question_focus(missing_slots)
        return policy

    # ASK_RECOMMEND: ì¶”ì²œ ìš”ì²­ì´ ì˜¨ ê²½ìš°ì—ë§Œ ì¶”ì²œ ëª¨ë“œ í™œì„±í™”
    if filled_count == 0:
        policy["reco_mode"] = "EXPLORE"
        policy["ask_question"] = True
        policy["question_focus"] = pick_question_focus(missing_slots)
    elif filled_count == 1:
        policy["reco_mode"] = "TOP3_CANDIDATES"
        policy["ask_question"] = True
        policy["question_focus"] = pick_question_focus(missing_slots)
    elif filled_count >= 2:
        policy["reco_mode"] = "TOP3_FINAL"
        policy["ask_question"] = turns_since_question >= 1
        policy["question_focus"] = "ì„ íƒ/ìš°ì„ ìˆœìœ„"

    return policy


# -------------------------
# Extraction parsing helper
# -------------------------
def extract_json_block(s: str) -> Optional[str]:
    if not s:
        return None
    s = s.strip()
    if s.startswith("{") and s.endswith("}"):
        return s
    m = re.search(r"\{.*\}", s, flags=re.DOTALL)
    return m.group(0) if m else None


def parse_extraction(parser: PydanticOutputParser, raw: str) -> ExtractionResult:
    try:
        return parser.parse(raw)
    except Exception:
        block = extract_json_block(raw)
        if not block:
            raise
        return parser.parse(block)


# -------------------------
# Streamlit App
# -------------------------
st.set_page_config(page_title="Career Chatbot MVP", page_icon="ğŸ’¬", layout="wide")
st.title("ğŸ’¬ Career Chatbot MVP (2-pass: ìƒë‹´ ëŒ€í™” + ì¡°ìš©í•œ ì •ë³´ì¶”ì¶œ)")

with st.sidebar:
    st.subheader("ì„¤ì •")
    api_key = st.text_input(
        "OPENAI_API_KEY (í™˜ê²½ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ë¹„ì›Œë„ ë¨)",
        type="password",
        value="",
        help="ë¡œì»¬ì—ì„œ í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì´ë¯¸ ì„¤ì •í–ˆìœ¼ë©´ ë¹„ì›Œë„ ë©ë‹ˆë‹¤.",
    )
    show_debug = st.toggle("ë””ë²„ê·¸ ë³´ê¸°", value=True)
    show_profile = st.toggle("í”„ë¡œí•„ JSON ë³´ê¸°", value=False)
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

# API Key ì²˜ë¦¬
if api_key:
    os.environ["OPENAI_API_KEY"] = api_key

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "profile" not in st.session_state:
    st.session_state.profile = UserProfile()
if "history" not in st.session_state:
    st.session_state.history = []  # langchain messages
if "chat" not in st.session_state:
    st.session_state.chat = []  # display messages: {"role": "user"/"assistant", "content": "..."}
if "turns_since_question" not in st.session_state:
    st.session_state.turns_since_question = 99

# LLM ë¦¬ì†ŒìŠ¤ ìºì‹œ
@st.cache_resource
def get_llms():
    chat_llm = ChatOpenAI(model="gpt-5.0", temperature=0.6)
    extract_llm = ChatOpenAI(model="gpt-5.0", temperature=0.0)
    return chat_llm, extract_llm


chat_llm, extract_llm = get_llms()
extract_parser = PydanticOutputParser(pydantic_object=ExtractionResult)

dialogue_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", DIALOGUE_SYSTEM_PROMPT),
        MessagesPlaceholder("history"),
        ("human", "{user_input}"),
    ]
)

extract_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", EXTRACT_SYSTEM_PROMPT),
        ("human", "user_message: {user_input}\n\ncurrent_profile_json: {current_profile_json}"),
    ]
)

# ê¸°ì¡´ ì±„íŒ… ë Œë”
for msg in st.session_state.chat:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì…ë ¥
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")
if user_input:
    # í™”ë©´ì— ìœ ì € ë©”ì‹œì§€
    st.session_state.chat.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    profile: UserProfile = st.session_state.profile
    history = st.session_state.history

    intent = detect_intent(user_input)
    filled_count, missing = compute_filled_and_missing(profile)

    policy = compute_policy(intent, filled_count, missing, st.session_state.turns_since_question)

    sys_vars = {
        "user_intent": intent,
        "filled_count": filled_count,
        "missing_slots": json.dumps(missing, ensure_ascii=False),
        "current_profile_json": json.dumps(profile.model_dump(), ensure_ascii=False),
        "ask_question": "true" if policy["ask_question"] else "false",
        "question_focus": policy["question_focus"],
        "reco_mode": policy["reco_mode"],
    }

    # (A) ìƒë‹´ ëŒ€í™” ìƒì„±
    messages = dialogue_prompt.format_messages(history=history[-6:], user_input=user_input, **sys_vars)
    assistant_text = chat_llm.invoke(messages).content.strip()

    # ì§ˆë¬¸ ë¹ˆë„ ì œì–´ìš©(ê°„ë‹¨ íœ´ë¦¬ìŠ¤í‹±)
    asked = ("?" in assistant_text) or assistant_text.strip().endswith(("ê¹Œ", "ìš”", "ë‹ˆ"))
    st.session_state.turns_since_question = 0 if (policy["ask_question"] and asked) else (st.session_state.turns_since_question + 1)

    # í™”ë©´ì— ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€
    st.session_state.chat.append({"role": "assistant", "content": assistant_text})
    with st.chat_message("assistant"):
        st.markdown(assistant_text)

    # history ì—…ë°ì´íŠ¸
    history.append(HumanMessage(content=user_input))
    history.append(AIMessage(content=assistant_text))
    st.session_state.history = history

    # (B) ì¡°ìš©í•œ ì •ë³´ì¶”ì¶œ
    try:
        extract_vars = {
            "format_instructions": extract_parser.get_format_instructions(),
            "user_input": user_input,
            "current_profile_json": json.dumps(profile.model_dump(), ensure_ascii=False),
        }
        raw_extract = extract_llm.invoke(extract_prompt.format_messages(**extract_vars)).content
        extraction = parse_extraction(extract_parser, raw_extract)

        profile = merge_profile(profile, extraction.profile_update)
        st.session_state.profile = profile

    except Exception as e:
        if show_debug:
            st.sidebar.error(f"ì¶”ì¶œ íŒŒì‹± ì˜¤ë¥˜: {e}")

    # ë””ë²„ê·¸/í”„ë¡œí•„ í‘œì‹œ
    if show_debug:
        filled_count2, missing2 = compute_filled_and_missing(st.session_state.profile)
        st.sidebar.write(
            {
                "intent": intent,
                "filled_count": filled_count2,
                "missing_slots": missing2,
                "policy": policy,
                "turns_since_question": st.session_state.turns_since_question,
            }
        )

    if show_profile:
        st.sidebar.subheader("current_profile_json")
        st.sidebar.code(json.dumps(st.session_state.profile.model_dump(), ensure_ascii=False, indent=2), language="json")
